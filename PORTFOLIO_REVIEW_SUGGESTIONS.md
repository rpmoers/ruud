# Portfolio copy suggestions (for review)

Suggested text changes based on the UX portfolio review. **Nothing has been applied yet** — review and tell me which items to apply (all, none, or by number).  
If you have EN content, the same logic can be applied there after you’re happy with the NL version.

---

## 1. HERE — Design System Modernisatie

### 1a. Role — clarify what you designed vs coordinated

**Field:** `role`  
**Why:** Review asked to distinguish what you designed/decided yourself vs facilitated.

**Current:**
> Senior UX Designer, met een begeleidende en adviserende rol in de modernisering van het design system. Verantwoordelijk voor richting geven aan UX-keuzes, bewaken van consistentie en ondersteunen van ontwerp- en ontwikkelteams.

**Suggested:**
> Senior UX Designer, met een begeleidende en adviserende rol in de modernisering van het design system. Ik gaf richting aan UX-keuzes (o.a. componentstructuur op gedrag en states, token-architectuur), bewaakte consistentie en ondersteunde ontwerp- en ontwikkelteams. De concrete componenten en documentatie zijn samen met de teams uitgewerkt en getest met een pilot voordat ze breder werden uitgerold.

*Adjust the “pilot” part if you didn’t do that — replace with whatever validation you did (e.g. “getest met 1–2 teams”).*

---

### 1b. Outcome — clarify why impact wasn’t measured

**Field:** `outcome`  
**Why:** So it reads as “no access to data” rather than “we didn’t measure.”

**Current (second paragraph):**
> Impact is niet kwantitatief gemeten, maar blijkt uit bredere adoptie, minder interpretatieverschillen tussen teams en hergebruik in meerdere productcontexten.

**Suggested:**
> Ik had geen toegang tot product- of adoptiemetrics na oplevering; impact blijkt uit bredere adoptie door teams, minder interpretatieverschillen en hergebruik in meerdere productcontexten.

---

## 2. Client Portal — Peterson

### 2a. Tasks — add research scope

**Field:** `tasks` (first bullet)  
**Why:** Review asked for scope of research (e.g. number of users/interviews).

**Current:**
> Uitvoeren van gebruikersonderzoek en interviews met verschillende klanttypes,

**Suggested (choose one or adapt):**
> Uitvoeren van gebruikersonderzoek en interviews met verschillende klanttypes (o.a. inkoop, verkoop, logistiek), op basis waarvan de dossier-gedreven structuur is gekozen.

*If you remember roughly how many interviews, you could add e.g. “(X interviews)” after “klanttypes”.*

---

### 2b. Outcome — clarify why no metrics

**Field:** `outcome`  
**Why:** Same as 1b — explicit “no access” sounds more professional.

**Current (second paragraph):**
> Impact is niet kwantitatief gemeten, maar blijkt uit kwalitatieve feedback en bredere adoptie door klanten.

**Suggested:**
> Er was geen toegang tot productmetrics na lancering; succes is afgeleid uit kwalitatieve feedback en bredere adoptie door klanten.

---

## 3. Design Systems — Wolters Kluwer

### 3a. Description — fix “twee voor een Europees cloud team”

**Field:** `description`  
**Why:** Review flagged inconsistency: “twee aparte” vs “één voor Duits, twee voor Europees”.

**Current:**
> Twee aparte design systems opgezet voor verschillende teams: één voor een Duits team en twee voor een Europees cloud team.

**Suggested (if it was really two systems in total):**
> Twee aparte design systems opgezet voor verschillende teams: één voor een product met complexe workflows en configuratie, één voor teams die snelheid en eenvoud nodig hadden.

*If the split was different (e.g. German vs European), adjust to match reality.*

---

### 3b. Decisions — add how you decided one vs two

**Field:** `decisions` (first bullet)  
**Why:** Review asked for one sentence on how the “one vs two systems” decision was made.

**Current:**
> Bewust gekozen voor twee afzonderlijke design systems in plaats van één universele oplossing, vanwege sterk uiteenlopende teambehoeften

**Suggested:**
> Na analyse van behoeften en workflows per team bewust gekozen voor twee afzonderlijke design systems in plaats van één universele oplossing, vanwege sterk uiteenlopende eisen (complexiteit en configuratie vs snelheid en eenvoud).

---

## 4. Portable Business Components — Wolters Kluwer

### 4a. Outcome — one concrete example + optional impact line

**Field:** `outcome`  
**Why:** Review: pick one component and briefly show the UX decision; add proxy for impact if you have it.

**Current (first part):**
> Binnen dit project zijn onder andere de volgende componenten ontwikkeld: Notification system voor consistente gebruikersmeldingen en statusupdates; Advanced Data Grid voor het tonen en beheren van complexe, gestructureerde data; Reporting system voor templatebeheer, documentgeneratie en configuratie; aanvullende business componenten voor terugkerende patronen binnen meerdere producten.

**Suggested (shortening and adding one example):**
> Binnen dit project zijn onder andere ontwikkeld: een Notification system voor consistente meldingen en statusupdates; een Advanced Data Grid voor complexe, gestructureerde data (met configuratie van kolommen en templates in plaats van per-product varianten); en een Reporting system voor templatebeheer en documentgeneratie. De Data Grid is als voorbeeld ontworpen rond vaste kernlogica en configuratie-opties, zodat teams geen eigen UX- en interactiebeslissingen hoefden te maken.

*Then keep or slightly shorten the rest of the outcome. If you have something like “in gebruik in X producten” or “vervangt Y custom builds”, add one sentence.*

---

## 5. TaskFlow & AI — Wolters Kluwer

### 5a. Outcome — frame as pre-launch + add one tough decision

**Field:** `outcome`  
**Why:** Review: make clear it’s pre-launch; add one concrete design decision (e.g. how you showed uncertainty or errors).

**Current:**
> Ontwerpen opgeleverd die klaar zijn voor integratie zodra de AI-functionaliteit beschikbaar komt. De focus ligt op duidelijke waarschuwingen, overzichtelijke samenvattingen en proactieve ondersteuning, zonder de bestaande gebruikersflow te onderbreken.
>
> De concepten zijn gevalideerd met stakeholders en eindgebruikers, met focus op UX, begrijpelijkheid en inpassing in de bestaande workflow.

**Suggested:**
> Ontwerpen opgeleverd die klaar zijn voor integratie zodra de AI-functionaliteit beschikbaar komt; impact is dus nog niet meetbaar. De focus lag op duidelijke waarschuwingen, overzichtelijke samenvattingen en proactieve ondersteuning, zonder de bestaande gebruikersflow te onderbreken. Een bewuste keuze was om bronverwijzingen en context bij AI-output zichtbaar te maken, zodat gebruikers kunnen controleren en vertrouwen kunnen opbouwen.
>
> De concepten zijn gevalideerd met stakeholders en eindgebruikers, met focus op UX, begrijpelijkheid en inpassing in de bestaande workflow.

*If “bronverwijzingen” wasn’t the main tough decision, replace that sentence with your actual example (e.g. how you handled “AI got it wrong” or confidence).*

---

## 6. Unilever Food Solutions App

### 6a. Role — clarify your personal scope

**Field:** `role`  
**Why:** Review: one sentence on what you personally designed vs led.

**Current:**
> UX Designer, later Lead UX Designer. Verantwoordelijk voor de UX van innovaties, websites en mobiele apps, met een toenemende focus op strategische richting, afstemming en begeleiding van teams.

**Suggested:**
> UX Designer, later Lead UX Designer. Ik was o.a. verantwoordelijk voor de UX van de Academy-module en het localization framework (structuur vs lokale content); daarnaast strategische richting, afstemming en begeleiding van teams over innovaties, websites en apps.

*Adjust “Academy-module en het localization framework” to what you actually owned.*

---

### 6b. Outcome — clarify no access to metrics

**Field:** `outcome`  
**Why:** Same as 1b and 2b.

**Current (second paragraph):**
> Impact is niet kwantitatief gemeten, maar blijkt uit langdurig gebruik van de app in meerdere markten en bredere adoptie van het platform.

**Suggested:**
> Ik had geen toegang tot gebruiks- of adoptiemetrics; impact blijkt uit langdurig gebruik in meerdere markten en bredere adoptie van het platform.

---

## 7. Waar Is Mijn Wegenwacht — ANWB

### 7a. Tasks — add research scope

**Field:** `tasks` (first and third bullet)  
**Why:** Review asked for scope of “klankbordgroep” and research.

**Current (first bullet):**
> Gebruikersonderzoek uitgevoerd om inzicht te krijgen in de behoeften en zorgen van gebruikers tijdens het wachten op de Wegenwacht.

**Suggested:**
> Gebruikersonderzoek uitgevoerd (interviews en/of klankbordgroep) om inzicht te krijgen in de behoeften en zorgen van gebruikers tijdens het wachten op de Wegenwacht.

**Current (third bullet):**
> Iteratief ontworpen en gevalideerd met een klankbordgroep van eindgebruikers, waarbij feedback is gebruikt om de interface verder te vereenvoudigen en verduidelijken.

**Suggested (if you remember scope):**
> Iteratief ontworpen en gevalideerd met een klankbordgroep van eindgebruikers [optioneel: van X personen], waarbij feedback is gebruikt om de interface verder te vereenvoudigen en verduidelijken.

*Only add “van X personen” if you know the number.*

---

### 7b. Decisions — add one trade-off

**Field:** `decisions`  
**Why:** Review: one “we chose X over Y because” to show reasoning.

**Current:** Three bullets describing features (statusweergave, live volgen, inzicht + wijzigen/annuleren).

**Suggested:** Keep the three, add a fourth that explains a trade-off, for example:
> Webapp gekozen boven native app vanwege bestaande infrastructuur en snellere realisatie, met acceptatie van beperkingen in push-notificaties.

*Adjust if the real trade-off was different.*

---

## 8. Interne AI-initiatieven — WARP

### 8a. Outcome or tasks — one concrete AI example

**Field:** `tasks` (last bullet) or `outcome`  
**Why:** Review: one concrete example of how AI was used (e.g. Cursor, handoff format).

**Current (task):**
> Verkennen van AI-ondersteuning als hulpmiddel in het design-to-development proces,

**Suggested:**
> Verkennen van AI-ondersteuning (o.a. Cursor) om vanuit Figma vastgelegde componentprops en states om te zetten naar front-end componenten, met engineers voor review en verfijning.

*If your flow was different (e.g. only documentation, or different tool), replace with that.*

---

## Summary

| #   | Project        | Field     | What changes |
|-----|----------------|-----------|--------------|
| 1a  | HERE           | role      | Clarify what you designed vs coordinated + validation (e.g. pilot) |
| 1b  | HERE           | outcome   | Explicit “geen toegang tot metrics” |
| 2a  | Peterson       | tasks     | Research scope / dossier-gedreven link |
| 2b  | Peterson       | outcome   | Explicit “geen toegang tot productmetrics” |
| 3a  | WK Design Sys  | description | Fix “twee voor Europees” → clear two systems |
| 3b  | WK Design Sys  | decisions | How “one vs two” was decided |
| 4a  | PBC            | outcome   | One component example (e.g. Data Grid) + optional impact |
| 5a  | TaskFlow & AI  | outcome   | Pre-launch framing + one concrete UX decision |
| 6a  | Unilever FS    | role      | Your personal scope (e.g. Academy, localization) |
| 6b  | Unilever FS    | outcome   | Explicit “geen toegang tot metrics” |
| 7a  | ANWB Wegenwacht| tasks     | Research/klankbordgroep scope |
| 7b  | ANWB Wegenwacht| decisions | One trade-off (e.g. webapp vs native) |
| 8a  | WARP AI        | tasks     | Concrete AI example (e.g. Cursor → components) |

After you review, say which numbers to apply (e.g. “apply 1a, 1b, 2a, 2b” or “apply all”) and whether to mirror changes in the EN content.
